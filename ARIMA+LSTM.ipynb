{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c988809-ca96-4b8c-a159-4d6c68310b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(\"C:\\\\Users\\\\A B Siddik\\\\Desktop\\\\ARIMA\\\\data.xlsx\")\n",
    "\n",
    "# Convert 'Date' column to datetime type\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Filter the data to include only the relevant dates\n",
    "data_filtered = data[(data['Date'] >= '2021-06-01') & (data['Date'] <= '2021-08-14')]\n",
    "\n",
    "# Extract the 'New COVID-19 Cases' column\n",
    "covid_cases = data_filtered['New COVID-19 Cases'].values\n",
    "\n",
    "# Train ARIMA model\n",
    "arima_model = ARIMA(covid_cases, order=(9, 2, 2))\n",
    "arima_fit = arima_model.fit()\n",
    "\n",
    "# Get residuals from ARIMA model\n",
    "residuals = arima_fit.resid\n",
    "\n",
    "# Normalize the residuals\n",
    "scaler = MinMaxScaler()\n",
    "residuals_scaled = scaler.fit_transform(residuals.reshape(-1, 1))\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 10\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        x.append(data[i-seq_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Create sequences for training\n",
    "x_train, y_train = create_sequences(residuals_scaled, seq_length)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=200, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=472, batch_size=22, verbose=1)\n",
    "\n",
    "# Print the model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecffbc0-1714-46f0-a146-1d80c6cc9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(\"C:\\\\Users\\\\A B Siddik\\\\Desktop\\\\ARIMA\\\\data.xlsx\")\n",
    "\n",
    "# Convert 'Date' column to datetime type\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Filter the data to include only the relevant dates\n",
    "data_filtered = data[(data['Date'] >= '2021-06-01') & (data['Date'] <= '2021-08-14')]\n",
    "\n",
    "# Extract the 'New COVID-19 Cases' column\n",
    "covid_cases = data_filtered['New COVID-19 Cases'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_end_date = '2021-07-17'\n",
    "test_start_date = '2021-07-18'\n",
    "\n",
    "train_data = data_filtered[data_filtered['Date'] <= train_end_date]['New COVID-19 Cases'].values\n",
    "test_data = data_filtered[data_filtered['Date'] >= test_start_date]['New COVID-19 Cases'].values\n",
    "\n",
    "# Train ARIMA model\n",
    "arima_model = ARIMA(train_data, order=(9, 2, 2))\n",
    "arima_fit = arima_model.fit()\n",
    "\n",
    "# Get residuals from ARIMA model\n",
    "train_residuals = arima_fit.resid\n",
    "\n",
    "# Normalize the residuals\n",
    "scaler = MinMaxScaler()\n",
    "train_residuals_scaled = scaler.fit_transform(train_residuals.reshape(-1, 1))\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 10\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        x.append(data[i-seq_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Create sequences for training\n",
    "x_train, y_train = create_sequences(train_residuals_scaled, seq_length)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=200, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=22, verbose=1)\n",
    "\n",
    "# Predict the test data with ARIMA\n",
    "arima_forecast = arima_fit.forecast(steps=len(test_data))\n",
    "arima_residuals = test_data - arima_forecast\n",
    "\n",
    "# Normalize the ARIMA residuals\n",
    "arima_residuals_scaled = scaler.transform(arima_residuals.reshape(-1, 1))\n",
    "\n",
    "# Create sequences for LSTM predictions\n",
    "x_test, y_test = create_sequences(arima_residuals_scaled, seq_length)\n",
    "\n",
    "# Predict the residuals with LSTM\n",
    "lstm_forecast_scaled = model.predict(x_test)\n",
    "\n",
    "# Rescale the LSTM predictions\n",
    "lstm_forecast = scaler.inverse_transform(lstm_forecast_scaled)\n",
    "\n",
    "# Combine ARIMA forecast and LSTM residual forecast\n",
    "final_forecast = arima_forecast[seq_length:] + lstm_forecast.flatten()\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(test_data[seq_length:], final_forecast)\n",
    "mae = mean_absolute_error(test_data[seq_length:], final_forecast)\n",
    "mape = np.mean(np.abs((test_data[seq_length:] - final_forecast) / test_data[seq_length:])) * 100\n",
    "rmse = np.sqrt(mse)\n",
    "rrmse = rmse / (np.max(test_data[seq_length:]) - np.min(test_data[seq_length:]))\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Relative Root Mean Square Error (RRMSE): {rrmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfba26ed-6dd4-42ae-b8d9-c1a13f66806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  # Ensure numpy is also imported if it's being used\n",
    "\n",
    "# Perform rolling forecasting between September 12, 2021, and September 18, 2021\n",
    "forecast_start_date = '2021-09-12'\n",
    "forecast_end_date = '2021-09-18'\n",
    "forecast_dates = pd.date_range(start=forecast_start_date, end=forecast_end_date)\n",
    "\n",
    "# Initialize history with the last `seq_length` sequences from training data\n",
    "history_cases = list(train_data[-seq_length:])\n",
    "history_residuals = list(train_residuals_scaled[-seq_length:])\n",
    "history_residuals = [seq[0] for seq in history_residuals]  # Ensure it's a list of scalar values\n",
    "\n",
    "rolling_forecast = []\n",
    "\n",
    "for date in forecast_dates:\n",
    "    # Use the ARIMA model to forecast the next value\n",
    "    arima_forecast_next = arima_fit.forecast(steps=1)[0]\n",
    "    history_cases.append(arima_forecast_next)\n",
    "    history_cases = history_cases[-seq_length:]  # Keep the length of history consistent\n",
    "\n",
    "    # Calculate the residuals\n",
    "    arima_residual_next = arima_forecast_next - (history_cases[-2] if len(history_cases) > 1 else arima_forecast_next)\n",
    "    history_residuals.append(scaler.transform([[arima_residual_next]])[0][0])\n",
    "    history_residuals = history_residuals[-seq_length:]  # Keep the length of history consistent\n",
    "\n",
    "    # Predict the residuals with LSTM\n",
    "    input_seq = np.array(history_residuals).reshape((1, seq_length, 1))\n",
    "    lstm_forecast_next_scaled = model.predict(input_seq)\n",
    "    lstm_forecast_next = scaler.inverse_transform(lstm_forecast_next_scaled)[0, 0]\n",
    "\n",
    "    # Combine ARIMA forecast and LSTM residual forecast\n",
    "    final_forecast_next = arima_forecast_next + lstm_forecast_next\n",
    "    rolling_forecast.append(final_forecast_next)\n",
    "\n",
    "# Rescale the forecasted values back to the original scale\n",
    "rolling_forecast_rescaled = scaler.inverse_transform(np.array(rolling_forecast).reshape(-1, 1))\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "rolling_forecast_combined_no_exo_df = pd.DataFrame(data=rolling_forecast_rescaled, index=forecast_dates, columns=['Forecast'])\n",
    "rolling_forecast_combined_no_exo_df['Forecast'] = np.abs(rolling_forecast_combined_no_exo_df['Forecast'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(rolling_forecast_combined_no_exo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b43ce0-bfa2-4665-8cb3-af0d02addb23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
