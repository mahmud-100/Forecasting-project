{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bde92f-de71-467f-bfbe-e68a50a5cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdee4d2-192c-49f9-90a8-9087199353d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fbdf11-6a09-4043-9044-12309cde7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel(\"C:\\\\Users\\\\A B Siddik\\\\Desktop\\\\ARIMA\\\\data.xlsx\")\n",
    "\n",
    "# Convert 'Date' column to datetime type\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Filter the data to include only the relevant dates\n",
    "data_filtered = data[(data['Date'] >= '2021-06-01') & (data['Date'] <= '2021-08-14')]\n",
    "\n",
    "# Extract the 'New COVID-19 Cases' column and normalize the data\n",
    "covid_cases = data_filtered['New COVID-19 Cases'].values\n",
    "scaler = MinMaxScaler()\n",
    "covid_cases_scaled = scaler.fit_transform(covid_cases.reshape(-1, 1))\n",
    "\n",
    "# Define the training period explicitly\n",
    "train_end_date = '2021-07-17'\n",
    "\n",
    "test_start_date = '2021-07-18'\n",
    "test_end_date = '2021-08-14'\n",
    "\n",
    "train_data = data_filtered[data_filtered['Date'] <= train_end_date]['New COVID-19 Cases'].values\n",
    "test_data = data_filtered[(data_filtered['Date'] >= test_start_date) & (data_filtered['Date'] <= test_end_date)]['New COVID-19 Cases'].values\n",
    "\n",
    "# Normalize train and test data\n",
    "train_data_scaled = scaler.fit_transform(train_data.reshape(-1, 1))\n",
    "test_data_scaled = scaler.transform(test_data.reshape(-1, 1))\n",
    "\n",
    "print(f\"train_data length: {len(train_data_scaled)}, test_data length: {len(test_data_scaled)}\")\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        x.append(data[i-seq_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "# Define sequence length\n",
    "\n",
    "seq_length = 10\n",
    "\n",
    "# Create sequences for training and testing\n",
    "x_train, y_train = create_sequences(train_data_scaled, seq_length)\n",
    "x_test, y_test = create_sequences(test_data_scaled, seq_length)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=200, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=472, batch_size=22, verbose=1)  # Reduced epochs for quicker debugging\n",
    "\n",
    "# Forecasting\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"y_pred shape: {y_pred.shape}\")\n",
    "\n",
    "# Rescale the predicted and true values back to the original scale\n",
    "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
    "mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "mape = np.mean(np.abs((y_test_rescaled - y_pred_rescaled) / y_test_rescaled)) * 100\n",
    "rmse = np.sqrt(mse)\n",
    "rrmse = rmse / (np.max(y_test_rescaled) - np.min(y_test_rescaled))\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Relative Root Mean Square Error (RRMSE): {rrmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc60ea-ed2f-4fc4-bbf9-0e9479a10f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Example: Generate synthetic training data\n",
    "n_samples = 100\n",
    "train_data = np.random.rand(n_samples, 1)  # Example 1D training data\n",
    "\n",
    "# Step 1: Scale the training data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 5  # Replace with the actual sequence length used in your model\n",
    "\n",
    "# Prepare sequences for training\n",
    "def create_sequences(data, seq_length):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        x.append(data[i-seq_length:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_train, y_train = create_sequences(train_data_scaled, seq_length)\n",
    "\n",
    "# Step 2: Build and train the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=8, verbose=1)\n",
    "\n",
    "# Step 3: Perform rolling forecasting\n",
    "forecast_start_date = '2021-09-12'\n",
    "forecast_end_date = '2021-09-18'\n",
    "forecast_dates = pd.date_range(start=forecast_start_date, end=forecast_end_date)\n",
    "\n",
    "# Initialize history with the last `seq_length` sequences from training data\n",
    "history = list(train_data_scaled[-seq_length:])\n",
    "history = [seq[0] for seq in history]  # Ensure it's a list of scalar values\n",
    "rolling_forecast = []\n",
    "\n",
    "for date in forecast_dates:\n",
    "    input_seq = np.array(history[-seq_length:]).reshape((1, seq_length, 1))\n",
    "    forecast = model.predict(input_seq)  # Ensure the `model` is defined and trained\n",
    "    rolling_forecast.append(forecast[0, 0])\n",
    "    history.append(forecast[0, 0])\n",
    "\n",
    "# Rescale the forecasted values back to the original scale\n",
    "rolling_forecast_rescaled = scaler.inverse_transform(np.array(rolling_forecast).reshape(-1, 1))\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "rolling_forecast_lstm_no_exo_df = pd.DataFrame(data=rolling_forecast_rescaled, index=forecast_dates, columns=['Forecast'])\n",
    "rolling_forecast_lstm_no_exo_df['Forecast'] = np.abs(rolling_forecast_lstm_no_exo_df['Forecast'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(rolling_forecast_lstm_no_exo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3810fa54-6f5a-4743-9bb7-ff577d11c089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
